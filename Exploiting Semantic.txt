The traditional supervised classifier for Text Categorization (TC) is learned from a set of hand-labeled documents.
However, the task of manual data labeling is labor intensive and time consuming, especially for a 
complex TC task with hundreds or thousands of categories. To address this issue, many semi-supervised methods
have been reported to use both labeled and unlabeled documents for TC. 
But they still need a small set of labeled data for each category.
In this paper, we propose a Fully Automatic Categorization approach for Text (FACT),
where no manual labeling efforts are required. In FACT, the lexical databases serve as 
semantic resources for category name understanding. It combines the semantic analysis of category names and 
statistic analysis of the unlabeled document set for fully automatic training data construction.
With the support of lexical databases, we first use the category name to generate a set of features as a
representative profile for the corresponding category.
Then, a set of documents is labeled according to the representative profile.
To reduce the possible bias originating from the category name and the representative profile, 
document clustering is used to refine the quality of initial labeling.
The training data are subsequently constructed to train the discriminative classifier. 
The empirical experiments show that one variant of our FACT approach outperforms the state-of-the-art unsupervised 
TC approach significantly. It can achieve more than 90% of F1 performance of the baseline SVM methods, 
which demonstrates the effectiveness of the proposed approaches.
